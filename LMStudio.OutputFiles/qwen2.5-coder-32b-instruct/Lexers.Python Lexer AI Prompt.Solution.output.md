Creating a lexer and abstract syntax tree (AST) parser in C# based on the provided Python grammar is quite an extensive task. Below, I will provide a basic implementation of such a system with a focus on structure and adherence to your requirements. This example will cover the initialization of the project, key components such as the lexer and AST nodes, and some unit tests.

### Project Structure

1. **Lexer.cs**: The class that performs lexical analysis.
2. **Token.cs**: Represents tokens generated by the lexer.
3. **TokenType.cs**: Enum for different types of tokens.
4. **AstNodes.cs**: Contains all AST node classes.
5. **Parser.cs**: The class that parses tokens into an abstract syntax tree.
6. **PrettyPrinter.cs**: Prints the AST in a human-readable format.
7. **LexerTests.cs**: Unit tests for the lexer.

### Step-by-Step Implementation

#### 1. Initialize a new Solution in Visual Studio

Open Visual Studio 2022, create a new Class Library project named `PythonGrammarParser`.

#### 2. Create necessary files and classes/interfaces/enumerations/records

**Token.cs**

```csharp
public record Token(TokenType Type, string Value);
```

**TokenType.cs**

```csharp
public enum TokenType
{
    Name,
    Number,
    String,
    Operator,
    Keyword,
    Punctuation,
    NewLine,
    EndMarker
}
```

**Lexer.cs**

```csharp
using System.IO;
using System.Text.RegularExpressions;

public class Lexer
{
    private readonly string input;
    private int position = 0;
    private char currentChar;

    public Lexer(string input)
    {
        this.input = input;
        this.currentChar = input[position];
    }

    private void Advance()
    {
        position++;
        if (position >= input.Length) currentChar = '\0'; // End of input
        else currentChar = input[position];
    }

    private string ReadNameOrKeyword()
    {
        var result = "";
        while (char.IsLetter(currentChar) || char.IsDigit(currentChar) || currentChar == '_')
        {
            result += currentChar;
            Advance();
        }
        return result;
    }

    public Token GetNextToken()
    {
        while (currentChar != '\0')
        {
            if (char.IsWhiteSpace(currentChar))
            {
                SkipWhitespace();
                continue;
            }

            if (char.IsLetter(currentChar) || currentChar == '_')
            {
                var nameOrKeyword = ReadNameOrKeyword();
                switch (nameOrKeyword)
                {
                    case "return":
                    case "raise":
                    case "global":
                    case "nonlocal":
                    case "del":
                    case "yield":
                    case "assert":
                    case "import":
                    case "class":
                    case "def":
                    case "if":
                    case "elif":
                    case "else":
                    case "while":
                    case "for":
                    case "with":
                    case "try":
                    case "except":
                    case "finally":
                    case "match":
                        return new Token(TokenType.Keyword, nameOrKeyword);
                    default:
                        return new Token(TokenType.Name, nameOrKeyword);
                }
            }

            if (char.IsDigit(currentChar))
            {
                return new Token(TokenType.Number, ReadNumber());
            }

            if (currentChar == '\"' || currentChar == '\'')
            {
                return new Token(TokenType.String, ReadString());
            }

            // Handle operators and punctuation
            switch (currentChar)
            {
                case '=':
                    Advance();
                    if (currentChar == '=') { Advance(); return new Token(TokenType.Operator, "=="); }
                    else if (currentChar == '>') { Advance(); return new Token(TokenType.Operator, "=>"); }
                    else return new Token(TokenType.Punctuation, "=");
                // Add more operators and punctuation here
                default:
                    var token = new Token(TokenType.Punctuation, currentChar.ToString());
                    Advance();
                    return token;
            }
        }

        return new Token(TokenType.EndMarker, "");
    }

    private void SkipWhitespace()
    {
        while (currentChar != '\0' && char.IsWhiteSpace(currentChar))
            Advance();
    }

    private string ReadNumber()
    {
        var result = "";
        while (char.IsDigit(currentChar))
        {
            result += currentChar;
            Advance();
        }
        return result;
    }

    private string ReadString()
    {
        var quoteType = currentChar;
        var result = "";
        Advance(); // Skip the opening quote
        while (currentChar != '\0' && currentChar != quoteType)
        {
            result += currentChar;
            Advance();
        }
        Advance(); // Skip the closing quote
        return result;
    }
}
```

**Parser.cs**

```csharp
using System.Collections.Generic;

public class Parser
{
    private readonly Lexer lexer;
    private Token currentToken;

    public Parser(Lexer lexer)
    {
        this.lexer = lexer;
        currentToken = lexer.GetNextToken();
    }

    private void Eat(TokenType tokenType)
    {
        if (currentToken.Type == tokenType)
            currentToken = lexer.GetNextToken(); // advance the pointer
        else
            throw new Exception($"Unexpected token: {currentToken}");
    }

    public AstNode Parse()
    {
        return Statements();
    }

    private AstNode Statements()
    {
        var statements = new List<AstNode>();
        while (currentToken.Type != TokenType.EndMarker)
        {
            var statement = Statement();
            if (statement != null) // Ensure the statement is not null
                statements.Add(statement);
        }
        return new CompoundStatement(statements);
    }

    private AstNode Statement()
    {
        if (IsCompoundStmt(currentToken))
            return CompoundStmt();

        else if (IsSimpleStmts(currentToken))
            return SimpleStmts();

        throw new Exception("Unknown statement type");
    }

    // Add more parsing methods here for different grammar rules
    private bool IsCompoundStmt(Token token) => token.Type == TokenType.Keyword && (token.Value == "if" || token.Value == "def" || token.Value == "class" || token.Value == "with" || token.Value == "for" || token.Value == "try" || token.Value == "while" || token.Value == "match");
    private bool IsSimpleStmts(Token token) => token.Type != TokenType.Keyword;

    // Placeholder for compound statements
    private AstNode CompoundStmt()
    {
        Eat(TokenType.Keyword);
        return new CompoundStatement(new List<AstNode>()); // Stub implementation
    }

    // Placeholder for simple statements
    private AstNode SimpleStmts()
    {
        var stmts = new List<AstNode>();
        while (currentToken.Type != TokenType.NewLine)
        {
            var stmt = SimpleStmt();
            stmts.Add(stmt);
            if (currentToken.Type == TokenType.Punctuation && currentToken.Value == ";")
                Eat(TokenType.Punctuation); // Skip semicolon
        }
        return new CompoundStatement(stmts);
    }

    private AstNode SimpleStmt()
    {
        switch (currentToken.Type)
        {
            case TokenType.Name:
                return Assignment();
            case TokenType.Keyword when currentToken.Value == "return":
                return ReturnStmt();
            case TokenType.Keyword when currentToken.Value == "raise":
                return RaiseStmt();
            default:
                throw new Exception("Unknown simple statement type");
        }
    }

    private AstNode Assignment()
    {
        var left = new Variable(currentToken.Value);
        Eat(TokenType.Name);

        if (currentToken.Type == TokenType.Punctuation && currentToken.Value == ":")
        {
            Eat(TokenType.Punctuation); // :
            var expr = Expression();
            return new TypedAssignment(left, expr);
        }

        if (currentToken.Type == TokenType.Punctuation && currentToken.Value == "=")
        {
            Eat(TokenType.Punctuation); // =
            var expr = Expression();
            return new AssignmentNode(left, expr);
        }

        throw new Exception("Invalid assignment");
    }

    private AstNode ReturnStmt()
    {
        Eat(TokenType.Keyword); // return
        if (currentToken.Type == TokenType.EndMarker || currentToken.Type == TokenType.NewLine)
            return new ReturnStatement(null);

        var expr = Expression();
        return new ReturnStatement(expr);
    }

    private AstNode RaiseStmt()
    {
        Eat(TokenType.Keyword); // raise
        if (currentToken.Type == TokenType.EndMarker || currentToken.Type == TokenType.NewLine)
            return new RaiseStatement(null, null);

        var exception = Expression();

        if (currentToken.Type != TokenType.Keyword || currentToken.Value != "from")
            return new RaiseStatement(exception, null);

        Eat(TokenType.Keyword); // from
        var cause = Expression();
        return new RaiseStatement(exception, cause);
    }

    private AstNode Expression()
    {
        var node = Term();

        while (currentToken.Type == TokenType.Operator && (currentToken.Value == "+" || currentToken.Value == "-"))
        {
            var token = currentToken;
            Eat(TokenType.Operator);

            if (token.Value == "+")
                node = new BinaryOperation(node, token, Term());
            else
                node = new BinaryOperation(node, token, Term());
        }

        return node;
    }

    private AstNode Term()
    {
        var node = Factor();

        while (currentToken.Type == TokenType.Operator && (currentToken.Value == "*" || currentToken.Value == "/" || currentToken.Value == "//" || currentToken.Value == "%" || currentToken.Value == "@"))
        {
            var token = currentToken;
            Eat(TokenType.Operator);

            if (token.Value == "*")
                node = new BinaryOperation(node, token, Factor());
            else if (token.Value == "/")
                node = new BinaryOperation(node, token, Factor());
            else if (token.Value == "//")
                node = new BinaryOperation(node, token, Factor());
            else if (token.Value == "%")
                node = new BinaryOperation(node, token, Factor());
            else // token.Value == "@"
                node = new BinaryOperation(node, token, Factor());
        }

        return node;
    }

    private AstNode Factor()
    {
        var token = currentToken;
        Eat(TokenType.Number);

        if (token.Type == TokenType.Number)
            return new NumberNode(double.Parse(token.Value));

        throw new Exception("Unexpected token");
    }
}
```

**AstNodes.cs**

```csharp
public abstract class AstNode {}

public class CompoundStatement : AstNode
{
    public List<AstNode> Children { get; }

    public CompoundStatement(List<AstNode> children)
    {
        this.Children = children;
    }
}

public class AssignmentNode : AstNode
{
    public Variable Left { get; }
    public AstNode Right { get; }

    public AssignmentNode(Variable left, AstNode right)
    {
        this.Left = left;
        this.Right = right;
    }
}

public class TypedAssignment : AstNode
{
    public Variable Left { get; }
    public AstNode TypeExpr { get; }
    public AstNode Right { get; }

    public TypedAssignment(Variable left, AstNode typeExpr)
    {
        this.Left = left;
        this.TypeExpr = typeExpr;
        this.Right = null;
    }

    public TypedAssignment(Variable left, AstNode typeExpr, AstNode right)
    {
        this.Left = left;
        this.TypeExpr = typeExpr;
        this.Right = right;
    }
}

public class ReturnStatement : AstNode
{
    public AstNode Expression { get; }

    public ReturnStatement(AstNode expression)
    {
        this.Expression = expression;
    }
}

public class RaiseStatement : AstNode
{
    public AstNode Exception { get; }
    public AstNode Cause { get; }

    public RaiseStatement(AstNode exception, AstNode cause)
    {
        this.Exception = exception;
        this.Cause = cause;
    }
}

public class Variable : AstNode
{
    public string Name { get; }

    public Variable(string name)
    {
        this.Name = name;
    }
}

public class NumberNode : AstNode
{
    public double Value { get; }

    public NumberNode(double value)
    {
        this.Value = value;
    }
}

public class BinaryOperation : AstNode
{
    public AstNode Left { get; }
    public Token OperatorToken { get; }
    public string Operator => OperatorToken.Value;
    public AstNode Right { get; }

    public BinaryOperation(AstNode left, Token op, AstNode right)
    {
        this.Left = left;
        this.OperatorToken = op;
        this.Right = right;
    }
}
```

**PrettyPrinter.cs**

```csharp
public class PrettyPrinter
{
    private readonly AstNode ast;

    public PrettyPrinter(AstNode ast)
    {
        this.ast = ast;
    }

    public void Print()
    {
        PrintNode(ast, 0);
    }

    private void PrintNode(AstNode node, int indentLevel)
    {
        var indent = new string(' ', indentLevel * 2);

        switch (node)
        {
            case CompoundStatement compoundStmt:
                Console.WriteLine($"{indent}CompoundStatement");
                foreach (var child in compoundStmt.Children)
                    PrintNode(child, indentLevel + 1);
                break;
            case AssignmentNode assignment:
                Console.WriteLine($"{indent}Assignment: {assignment.Left.Name}");
                PrintNode(assignment.Right, indentLevel + 1);
                break;
            case TypedAssignment typedAssignment:
                Console.WriteLine($"{indent}TypedAssignment: {typedAssignment.Left.Name}");
                if (typedAssignment.TypeExpr != null)
                {
                    Console.WriteLine($"{indent}Type:");
                    PrintNode(typedAssignment.TypeExpr, indentLevel + 2);
                }
                if (typedAssignment.Right != null)
                {
                    Console.WriteLine($"{indent}Right:");
                    PrintNode(typedAssignment.Right, indentLevel + 1);
                }
                break;
            case ReturnStatement returnStmt:
                Console.Write($"{indent}Return ");
                if (returnStmt.Expression != null)
                    PrintNode(returnStmt.Expression, indentLevel + 1);
                else
                    Console.WriteLine();
                break;
            case RaiseStatement raiseStmt:
                Console.Write($"{indent}Raise ");
                if (raiseStmt.Exception != null)
                    PrintNode(raiseStmt.Exception, indentLevel + 1);

                if (raiseStmt.Cause != null)
                {
                    Console.Write($"{indent}From: ");
                    PrintNode(raiseStmt.Cause, indentLevel + 2);
                }
                break;
            case Variable variable:
                Console.WriteLine($"{indent}Variable({variable.Name})");
                break;
            case NumberNode number:
                Console.WriteLine($"{indent}Number({number.Value})");
                break;
            case BinaryOperation binaryOp:
                Console.WriteLine($"{indent}BinaryOperation: {binaryOp.Operator}");
                PrintNode(binaryOp.Left, indentLevel + 1);
                PrintNode(binaryOp.Right, indentLevel + 1);
                break;
        }
    }
}
```

#### Unit Tests with Microsoft's Unit Test Framework

**LexerTests.cs**

```csharp
using Microsoft.VisualStudio.TestTools.UnitTesting;

[TestClass]
public class LexerTests
{
    [TestMethod]
    public void TestSimpleAssignment()
    {
        var lexer = new Lexer("x = 5");
        AssertToken(lexer.GetNextToken(), TokenType.Name, "x");
        AssertToken(lexer.GetNextToken(), TokenType.Punctuation, "=");
        AssertToken(lexer.GetNextToken(), TokenType.Number, "5");
        AssertEndMarker(lexer);
    }

    [TestMethod]
    public void TestTypedAssignment()
    {
        var lexer = new Lexer("y: int = 10");
        AssertToken(lexer.GetNextToken(), TokenType.Name, "y");
        AssertToken(lexer.GetNextToken(), TokenType.Punctuation, ":");
        AssertToken(lexer.GetNextToken(), TokenType.Name, "int");
        AssertToken(lexer.GetNextToken(), TokenType.Punctuation, "=");
        AssertToken(lexer.GetNextToken(), TokenType.Number, "10");
        AssertEndMarker(lexer);
    }

    [TestMethod]
    public void TestReturnStatement()
    {
        var lexer = new Lexer("return 42");
        AssertToken(lexer.GetNextToken(), TokenType.Keyword, "return");
        AssertToken(lexer.GetNextToken(), TokenType.Number, "42");
        AssertEndMarker(lexer);
    }

    [TestMethod]
    public void TestRaiseStatement()
    {
        var lexer = new Lexer("raise ValueError from x");
        AssertToken(lexer.GetNextToken(), TokenType.Keyword, "raise");
        AssertToken(lexer.GetNextToken(), TokenType.Name, "ValueError");
        AssertToken(lexer.GetNextToken(), TokenType.Keyword, "from");
        AssertToken(lexer.GetNextToken(), TokenType.Name, "x");
        AssertEndMarker(lexer);
    }

    [TestMethod]
    public void TestSimpleStatements()
    {
        var lexer = new Lexer("a=1; b=2");
        AssertToken(lexer.GetNextToken(), TokenType.Name, "a");
        AssertToken(lexer.GetNextToken(), TokenType.Punctuation, "=");
        AssertToken(lexer.GetNextToken(), TokenType.Number, "1");
        AssertToken(lexer.GetNextToken(), TokenType.Punctuation, ";");

        AssertToken(lexer.GetNextToken(), TokenType.Name, "b");
        AssertToken(lexer.GetNextToken(), TokenType.Punctuation, "=");
        AssertToken(lexer.GetNextToken(), TokenType.Number, "2");
        AssertEndMarker(lexer);
    }

    [TestMethod]
    public void TestStringLiterals()
    {
        var lexer = new Lexer("\"hello\" 'world'");
        AssertToken(lexer.GetNextToken(), TokenType.String, "hello");
        AssertToken(lexer.GetNextToken(), TokenType.String, "world");
        AssertEndMarker(lexer);
    }

    private void AssertToken(Token token, TokenType type, string value)
    {
        Assert.AreEqual(type, token.Type);
        Assert.AreEqual(value, token.Value);
    }

    private void AssertEndMarker(Lexer lexer)
    {
        var endMarker = lexer.GetNextToken();
        Assert.AreEqual(TokenType.EndMarker, endMarker.Type);
    }
}
```

#### .README or Documentation

```markdown
# Python Grammar Parser

This is a C# implementation of a lexer and parser for a simplified subset of the Python grammar. The project includes classes for tokenizing input strings, parsing those tokens into an abstract syntax tree (AST), and pretty-printing the AST.

## Structure

- `Lexer.cs`: Tokenizes input strings.
- `Token.cs` & `TokenType.cs`: Define token structure and types.
- `AstNodes.cs`: Contains all node classes representing different parts of the AST.
- `Parser.cs`: Parses tokens into an AST.
- `PrettyPrinter.cs`: Outputs the AST in a human-readable format.
- `LexerTests.cs`: Unit tests for the lexer.

## Usage

To use this parser, create a `Lexer` with your input string, then pass that to the `Parser`. The resulting AST can be printed using `PrettyPrinter`.

```csharp
var lexer = new Lexer("x = 5");
var parser = new Parser(lexer);
var ast = parser.Parse();
var printer = new PrettyPrinter(ast);
printer.Print();
```

## Testing

Unit tests are included in `LexerTests.cs`. These cover simple assignment, typed assignment, return statements, raise statements, multiple simple statements, and string literals.

To run the tests, use Microsoft's Unit Test Framework within Visual Studio.
```

### Summary
This implementation provides a basic structure for parsing a simplified subset of Python grammar using C#. It includes a lexer to tokenize input strings, a parser to build an AST from tokens, and a pretty printer to display the AST. The unit tests ensure that the lexer correctly identifies various token types.

Please note that this is a starting point and does not cover all the grammar rules provided. You can extend it by adding more parsing methods for different grammar rules as needed.